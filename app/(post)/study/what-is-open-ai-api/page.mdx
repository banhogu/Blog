---
title: OpenAI API 이해하기
tag: study
description: OpenAI API, 생성형 AI, LLM, GPT에 대해 알아봅시다.
subTitle: OpenAI API, 생성형 AI, LLM, GPT에 대해 알아봅시다.
date: 2024-07-04
---

import { FileName } from '@/components/ui/FileName';
import { Callout } from '@/components/ui/callout';

<div className="flex justify-end">
  [다음 글](https://www.banghojin.site/experience/improve-gpt-response)
</div>

## 개요

나만의 Next.js 블로그를 더욱 유용하게 만들기 위해 다양한 기능들을 추가하고 있는데, 그 중 하나가 바로 글을 요약해주는 AI 요약 기능이다. 이 기능을 통해 독자들은 긴 글을 빠르게 이해할 수 있고, 중요한 정보들만을 요약하여 볼 수 있게 된다.

해당 기능을 구현하기 위해서 OpenAI에서 제공하는 API를 선택했는데, OpenAI API는 강력한 자연어 처리 성능을 제공하며, 이를 통해 코드나 텍스트를 다양한 방식으로 답변하며 심지어는 이미지까지 제공해준다. 해당 기능을 구현하기 전 OpenAI API를 이해하고 효과적으로 사용하는 것이 필수적이라고 생각되어, 이번 글에서는 Next.js 블로그 프로젝트에 AI 요약 기능을 적용하기 위해 필요한 OpenAI API, 생성형 AI, LLM에 관한 내용에 대해 **하향식 접근으로** 알아볼 것이다.

<br />

## openAI API

### OpenAI API란?

![](/images/study/what-is-open-ai-api/1.png)

OpenAI API는 OpenAI에서 개발한 인공지능 모델을 프로그래밍 인터페이스로 제공하며, 외부 애플리케이션에서 이를 유연하게 활용할 수 있도록 만든 API이다. 애플리케이션에 쉽게 통합하여 새로운 AI 기반 기능을 통해, 기존 성능을 향상시킬 수 있도록 다양한 기능을 제공한다.<br/><br/>
개발자 사이에서 가장 잘 알려진 OpenAI의 API는 ChatGP이다. ChatGPT는 인간 처럼 대화하는 인공지능 모델로서 매우 광범위한 활용 범위를 가지고 있다. ChatGPT뿐만 아니라 OpenAI의 API는 다양한 시나리오에서 사용될 수 있는 많은 다양한 기능과 활용 사례를 가진 여러 인공 지능 모델들을 포함하고 있다.

<br />

### ChatGPT

![](/images/study/what-is-open-ai-api/2.png)

ChatGPT는 사용자의 질문에 대해 자연스러운 언어로 답변을 생성하도록 설계된 대화형 인공지능 모델이다. 이 모델은 고객지원부터 개인 비서, 교육용 도구 등 다양한 응용 분야에서 사용 되고 있는데, GPT-3 기반으로 설계되었으며, 자연스러운 대화 흐름과 맥락을 통해 정확한 답변을 제공해준다.

<br />

### 기타 OpenAI API 모델

OpenAI는 ChatGPT 외에도, 다양한 목적에 사용할 수 있는 여러 AI 모델들을 API 형태로 제공한다

- **텍스트 생성 API:** 주어진 프롬프트(텍스트)를 기반으로 일관된 텍스트를 창의적으로 생성하는 기능을 제공한다. 블로그 게시물 작성, 소설 작성, 스크립트 작성 등 다양한 분야의 콘텐츠 생성에 활용될 수 있다.
- **텍스트 요약 API:** 길고 복잡한 텍스트를 간결하게 요약해주는 기능을 제공한다. 뉴스 기사, 연구 논문, 블로그 포스트 등의 긴 내용을 요약하거나, 중요한 정보만을 추출하는데 유용하다.
- **번역 API:** 여러 언어 간의 번역을 자동으로 처리하는 기능을 제공한다. 국제적으로 사용하는 애플리케이션, 다국어 지원이 필요한 프로젝트 등에서 활용할 수 있다.

<br />

## 생성형 AI

### 생성형 인공지능(Generative AI)의 개념

![](/images/study/what-is-open-ai-api/3.png)

생성형 인공지능(Generative AI)은 기계 학습(ML) 모델의 한 유형으로, 새로운 데이터나 콘텐츠를 생성하는 데 특화된 기술을 의미한다. 이는 기존 데이터를 학습하여 새로운 데이터 샘플을 생성함으로써, **기존 데이터를 활용한 예측 시스템과는 다르게 작동한다.** 생성형 AI는 수많은 가능성을 탐구하고 새로운 정보를 산출하며, 이는 텍스트, 이미지, 음성, 음악 등 다양한 형태로 구현될 수 있다.

**예측 시스템과 생성형 AI의 차이점**

- **예측 시스템:** 주어진 데이터로부터 패턴을 학습하여 미래의 데이터를 예측한다. 예를 들어, 과거의 판매 데이터를 기반으로 향후 매출을 예측하는 모델이다.
- **생성형 AI:** 주어진 데이터를 학습하여 새로운 데이터나 콘텐츠를 생성한다. 예를 들어, 기존 문학 작품 스타일을 학습하고 새로운 이야기를 작성하는 모델이다.<br /><br />

### 생성형 AI의 작동 원리

그림을 그리는 AI 예제로 설명해보자면, 순서는 다음과 같다.

**데이터 학습**
-> 생성형 AI는 먼저 다수의 AI가 배워야 할 패턴과 특징을 포함한 그림 데이터를 학습한다. 예를 들어, 고양이의 그림이 많이 포함된 데이터셋을 학습한다고 하면, AI는 이 데이터셋을 통해 고양이 그림의 다양한 특징들 예를 들어, 고양이의 귀 모양, 눈의 위치, 몸의 비율 등을 학습한다.<br /><br />

**생성 과정**
-> 학습이 완료된 후에는, AI가 새로운 고양이 그림을 생성할 수 있다. 이를 위해 주로 사용되는 방법 중 하나가 "생성자(Generator)"와 "판별자(Discriminator)"가 서로 경쟁하는 GAN(Generative Adversarial Networks)이다.

- 생성자(Generator)**:** 생성자는 무작위로 편집된 잡음을 입력으로 받아 고양이 그림을 생성.
- 판별자(Discriminator)**:** 판별자는 입력된 그림이 실제인지 가짜인지 구별하는 역할을 한다. 학습 데이터를 기반으로, 판별자는 생성된 그림이 실제 고양이 그림과 얼마나 유사한지 평가한다.

생성자와 판별자는 서로 경쟁하면서 완성도를 높여나간다. 생성자는 판별자를 속이기 위해 점점 더 실제 같은 고양이 그림을 생성하려 하고, 판별자는 이러한 속임수를 알아차리기 위해 더 정확하게 학습한다. 이 과정이 반복되면서, 생성자는 점점 더 정교하고 실제 같은 고양이 그림을 생성할 수 있게 되는것이다.<br /><br />

**결과**
-> 최종적으로 학습이 완료되면, 생성자는 기존에 없던 새로운 고양이 그림을 만들 수 있게 되며, 해당 작업은 텍스트 생성, 음악 생성, 음성 합성 등 다른 형태의 생성 작업으로 확장될 수 있다.

<br />

## LLM

### LLM(Large Language Model)의 개념

LLM은 인공지능 분야에서 자연어 처리 작업을 수행하기 위해 개발된 강력한 도구이다. LLM은 수백만 개 이상의 매개변수를 가지며, 이를 통해 방대한 양의 텍스트 데이터를 학습하여 언어의 패턴과 구조를 이해하고 생성할 수 있다. LLM의 대표적인 예로는 OpenAI에서 개발한 GPT 시리즈가 있다. 해당 모델들은 웹 페이지, 책, 논문, 기사 등 다양한 출처의 대규모 텍스트 데이터셋에서 사전 훈련되며, 그 결과로 텍스트 생성, 분류, 번역, 질문 응답, 감정 분석 등 다양한 자연어 처리 작업에 유용하게 활용되고 있다.<br /><br />

### LLM의 주요 특징

1. **방대한 매개변수**: LLM은 수백만 개 이상의 매개변수를 통해 매우 복잡한 언어 패턴과 구조를 학습한다. 이는 모델이 문장의 의미를 더 깊이 이해하고 자연스러운 텍스트를 생성하는 데 기여한다.
2. **다양한 응용 분야**: LLM은 현재 많은 상업적 응용 프로그램에서 사용되고 있다. 예를 들어, 챗봇, 검색 엔진, 자동 번역 서비스, 컨텐츠 추천 시스템 등 다양한 분야에서 그 가치가 인정받고 있다.
3. **자연스러운 텍스트 생성**: LLM은 매우 정교하고 자연스러운 텍스트를 생성할 수 있다. 이는 인간과의 상호작용에서 중요한 역할을 하며, 사용자 경험을 크게 향상시킨다.
4. **광범위한 학습 데이터**: LLM은 다양한 출처에서 수집된 대규모 텍스트 데이터를 학습하여 언어 모델의 성능을 극대화한다. 이는 모델이 여러 언어와 주제에 대해 높은 이해도를 가지게 한다.<br /><br />

### LLM 학습의 기본 원리: 언어 모델 (Language Model, LM) ⭐️

![](/images/study/what-is-open-ai-api/4.png)

언어 모델은 텍스트 데이터를 기반으로 다음에 올 단어가 무엇일지를 예측하는 방식으로 학습된다. 예를 들어, "푸른 하늘에 00이 떠있다."라는 문장에서 00에 들어갈 단어를 예측하는 것이다. 사람은 이 문맥에서 "구름"이 들어가야 자연스럽다고 쉽게 판단할 수 있다. 언어 모델은 이와 같은 예측을 머신러닝 기법을 통해 학습하게 된다.

- **입력 문장**: 00 하늘에 구름이 떠있다.
  - **정답**: 푸른
- **입력 문장**: 푸른 00에 구름이 떠있다.
  - **정답**: 하늘
- **입력 문장**: 푸른 하늘에 00이 떠있다.
  - **정답**: 구름
- **입력 문장**: 푸른 하늘에 구름이 000.
  - **정답**: 떠있다. <br /><br />

### LLM의 입출력 및 학습 방법

1. **데이터 준비**: 언어 모델을 훈련시키기 위해서는 대규모의 텍스트 데이터가 필요하다. 해당 데이터는 웹 페이지, 책, 논문, 기사 등 다양한 출처에서 수집될 수 있다.
2. **입력 및 목표 설정**: 모델은 주어진 문맥(입력)에서 다음 단어(목표)를 예측하는 방식으로 학습된다. 예를 들어, **"푸른 하늘에 00이 떠있다."**라는 문장에서 00을 예측하는 것이 목표로 정한다.
3. **모델 훈련**: 모델은 입력과 목표 데이터를 통해 패턴을 학습한다. 모델이 예측한 단어와 실제 정답 단어 사이의 오차를 줄이는 방향으로 매개변수들이 조정되는데, 이 과정을 반복하면서 모델은 점점 더 정확한 예측을 할 수 있게 된다.
4. **예측 및 생성**: 훈련이 완료된 모델은 새로운 문장을 입력받아 다음에 올 단어를 예측할 수 있다. 예를 들어, "푸른 하늘에"라는 문장을 입력받으면 모델은 "구름이"라는 단어를 예측할 수 있게 된다. 대표적인 예로는 검색 엔진의 자동 완성 기능이 있다. 사용자가 검색어를 입력할 때 검색어 뒤에 올 단어를 제안하는 기능은 언어 모델이 실시간으로 다음 단어를 예측하는 과정을 기반으로 한다.

<Callout>
💡 정리하자면, 대규모 언어 모델(LLM)은 주어진 문맥에서 다음에 올 단어를 예측하는 언어 모델(LM)을 기반으로 학습된다. 이 과정에서 모델은 대규모의 텍스트 데이터를 통해 언어의 패턴과 구조를 학습하고, 이를 바탕으로 다양한 자연어 처리 작업을 수행할 수 있게 된다.

</Callout>

<br />

## GPT

### GPT(Generative Pre-trained Transformer)의 개념

![](/images/study/what-is-open-ai-api/5.png)

GPT는 LLM의 대표적인 예시로, OpenAI에서 개발한 자연어 처리 모델이다. GPT는 트랜스포머 아키텍처를 기반으로 하여, 대규모 텍스트 데이터를 학습한 후 다양한 자연어 처리 작업을 수행할 수 있는 능력을 갖추고 있다. GPT 시리즈는 여러 버전이 있으며, 각각의 버전이 발전하면서 성능이 향상 되고 있다.<br /><br />

### GPT의 동작 원리

**트랜스포머 아키텍처**:

- GPT는 **트랜스포머 아키텍처**를 사용하여 설계되었다. 트랜스포머는 **셀프 어텐션 메커니즘**을 활용하여 문맥을 더 잘 이해하고, 병렬 처리를 통해 효율적으로 학습할 수 있다

<Callout>
💡 트랜스포머는 자연어 처리 분야에서 혁신적인 모델 아키텍처로, 기계 번역, 텍스트 요약, 질문 응답 등 다양한 작업에서 뛰어난 성능을 발휘한다. 2017년에 구글의 연구팀이 논문을 통해 처음 소개했다. 트랜스포머는 **셀프 어텐션 메커니즘**과 병렬 처리 능력을 통해 기존의 순차적인 처리 방식보다 훨씬 효율적이고 효과적으로 언어를 이해하고 생성할 수 있다.예를 들어, "그녀는 사과를 먹었다. 그것은 맛있었다."라는 문장이 있을 때, 셀프 어텐션 메커니즘은 "그것"이 "사과"를 가리키고 있다는 것을 파악한다. 즉, "그것"이라는 단어가 앞 문장의 "사과"와 관련이 있다는 것을 알아차린다.

</Callout>

<br />

**사전 훈련과 미세 조정**

**사전 훈련 (Pre-training)**

- GPT는 대규모의 일반 텍스트 데이터로 사전 훈련을 한다. 이 과정에서 모델은 다양한 주제와 형식의 텍스트를 읽으며 언어의 기본적인 패턴과 구조를 학습한다.
- **예시**
  - GPT가 일종의 학생이라고 할 때, 사전 훈련은 이 학생이 수많은 책, 신문, 웹사이트를 읽는 과정이다. 이 과정을 통해 문법, 어휘, 일반적인 문장 구조를 배우고, 다양한 주제에 대한 기본적인 지식을 습득한다.
  - 예를 들어, "그녀는 사과를 먹었다. 그것은 맛있었다." 같은 문장을 읽으면서 '그녀'라는 단어가 주어로, ‘먹었다’가 동사로 사용된다는 것을 배운다. 수천만 개의 이런 문장을 읽다 보면, 텍스트의 일반적인 패턴과 구조를 이해하게 된다.<br /><br />

**미세 조정 (Fine-tuning)**

- 미세 조정을 통해 모델을 더욱 정교하게 조정한다. 즉 특정 도메인이나 응용 프로그램에 맞게 최적화하는 과정이라고 할 수 있다.
- **예시**
  - 다시 학생의 예를 들어보자면, 이제 이 학생이 법률 시험을 준비한다고 가정해본다. 사전 훈련에서 일반적인 지식을 습득한 후, 이제는 법률 서적과 사례 연구를 집중적으로 공부한다. 이를 통해 법률 관련 질문에 더 정확하고 적절한 답변을 할 수 있게 된다.
  - 구체적으로, 모델이 "계약서 작성"에 대한 작업을 미세 조정한다면, 모델은 사전 훈련된 일반 지식 위에 법률 문서와 계약서 샘플을 추가로 학습하여, 계약서 작성의 문법, 용어, 형식을 더 잘 이해하고 작성할 수 있다.

<br />
